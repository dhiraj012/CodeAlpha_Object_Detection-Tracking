{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d7625c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python opencv-python-headless numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520683df",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276d7607",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807105ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision opencv-python-headless"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa416ab",
   "metadata": {},
   "source": [
    "# Real-Time Object Detection and Tracking with Faster R-CNN\n",
    "\n",
    "## Overview\n",
    "\n",
    "This project demonstrates the use of **Faster R-CNN**, a deep learning model for object detection, to detect and track objects in real-time video streams. By leveraging a pre-trained Faster R-CNN model, we can identify a variety of objects such as people, cars, animals, and more, with high accuracy and efficiency. The model is capable of processing each frame in real-time to detect and draw bounding boxes around the detected objects.\n",
    "\n",
    "### Key Features:\n",
    "- **Real-time object detection** using Faster R-CNN.\n",
    "- **Pre-trained model** (ResNet-50 with Feature Pyramid Networks).\n",
    "- **Live webcam or video input** for real-time detection.\n",
    "- **Multiple object classification** from the COCO dataset (80+ categories).\n",
    "- **Bounding box visualization** with labels for each detected object.\n",
    "\n",
    "---\n",
    "\n",
    "## Technology Stack\n",
    "\n",
    "- **Python**: Primary programming language for implementation.\n",
    "- **PyTorch**: Deep learning framework for Faster R-CNN model.\n",
    "- **OpenCV**: Computer vision library for video processing and displaying results.\n",
    "- **Torchvision**: Provides pre-trained Faster R-CNN model.\n",
    "\n",
    "---\n",
    "\n",
    "## Installation\n",
    "\n",
    "Follow the steps below to set up the project on your local machine:\n",
    "\n",
    "1. Clone this repository:\n",
    "   ```bash\n",
    "   git clone https://github.com/your-username/object-detection.git\n",
    "   cd object-detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dc360c",
   "metadata": {},
   "source": [
    "# Dependencies:\n",
    "\n",
    "torch\n",
    "torchvision\n",
    "opencv-python\n",
    "Pillow\n",
    "numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdc4b6e",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "\n",
    "Input Frames: Video frames are captured using OpenCV from a webcam or video file.\n",
    "Preprocessing: Frames are converted into tensors for model input.\n",
    "Object Detection: The Faster R-CNN model detects objects, outputs bounding boxes, labels, and confidence scores.\n",
    "Visualization: Detected objects are highlighted with bounding boxes and labels using OpenCV.\n",
    "Display & Exit: The processed frames are displayed in real-time, and the program can be exited with the Esc key or by closing the window.\n",
    "\n",
    "Features -\n",
    "\n",
    "Real-Time Detection: Processes frames sequentially for live object detection.\n",
    "Accuracy: Utilizes a pre-trained COCO dataset model for detecting 80+ object classes.\n",
    "Applications: Useful in surveillance, autonomous vehicles, and smart camera systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f4591f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhira\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dhira\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "# Load pre-trained Faster R-CNN model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# Define COCO dataset classes\n",
    "COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant',\n",
    "    'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'N/A', 'N/A', 'handbag', 'tie',\n",
    "    'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat',\n",
    "    'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'N/A',\n",
    "    'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich',\n",
    "    'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "    'potted plant', 'bed', 'N/A', 'dining table', 'N/A', 'N/A', 'toilet', 'N/A', 'tv',\n",
    "    'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven',\n",
    "    'toaster', 'sink', 'refrigerator', 'N/A', 'book', 'clock', 'vase', 'scissors',\n",
    "    'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "# Function to draw bounding boxes and labels\n",
    "def draw_boxes(image, boxes, labels, scores, threshold=0.5):\n",
    "    for i, box in enumerate(boxes):\n",
    "        if scores[i] > threshold:\n",
    "            label = COCO_INSTANCE_CATEGORY_NAMES[labels[i]]\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    return image\n",
    "\n",
    "# Open webcam or video file\n",
    "cap = cv2.VideoCapture(0)  # Use 'filename.mp4' for video file\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open video source\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Unable to read frame from video source\")\n",
    "        break\n",
    "\n",
    "    # Preprocess the frame\n",
    "    input_tensor = F.to_tensor(frame).unsqueeze(0).to(device)\n",
    "\n",
    "    # Perform object detection\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor)\n",
    "\n",
    "    # Parse the outputs\n",
    "    boxes = outputs[0]['boxes'].cpu().numpy()\n",
    "    labels = outputs[0]['labels'].cpu().numpy()\n",
    "    scores = outputs[0]['scores'].cpu().numpy()\n",
    "\n",
    "    # Draw the bounding boxes on the frame\n",
    "    frame = draw_boxes(frame, boxes, labels, scores)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Object Detection\", frame)\n",
    "\n",
    "    # Close the window on 'Esc' key press or 'X' button click\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == 27 or cv2.getWindowProperty(\"Object Detection\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "        break\n",
    "\n",
    "# Release resources and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884a85f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
